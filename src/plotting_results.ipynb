{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import datetime\n",
    "from kaleido.scopes.plotly import PlotlyScope\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from src.db_handler import retrieve_all_data\n",
    "rcParams['figure.figsize'] = (17, 10)\n",
    "sns.set_theme(context='talk', style='whitegrid')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT  TWEET_CREATED,\n",
    "        CONVERSATION_ID,\n",
    "        TWEET_ID,\n",
    "        AUTHOR_ID,\n",
    "        TWEET_TEXT,\n",
    "        RETWEET_COUNT,\n",
    "        REPLY_COUNT,\n",
    "        LIKE_COUNT,\n",
    "        QUOTE_COUNT,\n",
    "        ACCOUNT_CREATED,\n",
    "        ACCOUNT_ID,\n",
    "        ACCOUNT_NAME,\n",
    "        VERIFIED,\n",
    "        FOLLOWER_COUNT,\n",
    "        FOLLOWING_COUNT,\n",
    "        TWEET_COUNT,\n",
    "        LISTED_COUNT,\n",
    "        WORD_UNIQUENESS,\n",
    "        SENTIMENT\n",
    "FROM preprocessed_tweets\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows have been retrieved\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(retrieve_all_data(query=query), columns=['tweet_created', 'conversation_id', 'tweet_id', 'author_id', 'text', 'retweet_count', 'reply_count', 'like_count', 'quote_count', 'account_created', 'account_id', 'name', 'verified', 'follower_count', 'following_count', 'tweet_count', 'listed_count', 'word_uniqueness_%', 'sentiment'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                tweet_created      conversation_id             tweet_id  \\\n0      2022-06-11 01:15:29+03  1535385188557103105  1535385188557103105   \n1      2022-06-10 22:48:24+03  1535348174168236032  1535348174168236032   \n2      2022-06-10 22:08:11+03  1535338052746366977  1535338052746366977   \n3      2022-06-10 22:03:21+03  1535336834070372353  1535336834070372353   \n4      2022-06-10 21:40:31+03  1535331088154902529  1535331088154902529   \n...                       ...                  ...                  ...   \n45681  2022-06-21 22:17:15+03  1539305669928669190  1539326600340193280   \n45682  2022-06-21 22:09:00+03  1539305669928669190  1539324523635298306   \n45683  2022-06-21 21:03:18+03  1539305669928669190  1539307989001089026   \n45684  2022-06-21 20:57:48+03  1539305669928669190  1539306607338786818   \n45685  2022-06-21 22:00:34+03  1539306518939676672  1539322401728647169   \n\n                 author_id                                               text  \\\n0                361289499  Texas governor candidate Don Huffines: \" Bitco...   \n1                361289499  - Grayscale and Bitwise are confident a spot B...   \n2                361289499  Thanks to for publishing my article covering t...   \n3                361289499  Very honored that my list of Bitcoin privacy p...   \n4                361289499  \"And then we told them the inflation would not...   \n...                    ...                                                ...   \n45681  1287057962155094018                       so cool, never stop evolving   \n45682  1333917637068242944  if you want some sh*tty old trucks to paint IR...   \n45683  1317225065411346432  yesssss lets go, good investment ahhhhhh this ...   \n45684               432093                   how much more epic can you get??   \n45685           1652517409  Well deserved, BT. Your Metaversal release was...   \n\n       retweet_count  reply_count  like_count  quote_count  \\\n0                492          267        3309           32   \n1                572          258        3743           32   \n2                 34            0           0            0   \n3                 68            0           0            0   \n4                443          135        2895           28   \n...              ...          ...         ...          ...   \n45681              0            0           2            0   \n45682              0            0           2            0   \n45683              0            0           0            0   \n45684              0            0           0            0   \n45685              0            0           2            0   \n\n                account_created           account_id  \\\n0      2011-08-24T15:14:54.000Z            361289499   \n1      2011-08-24T15:14:54.000Z            361289499   \n2      2011-08-24T15:14:54.000Z            361289499   \n3      2011-08-24T15:14:54.000Z            361289499   \n4      2011-08-24T15:14:54.000Z            361289499   \n...                         ...                  ...   \n45681  2020-07-25T16:11:56.000Z  1287057962155094018   \n45682  2020-12-01T23:35:46.000Z  1333917637068242944   \n45683  2020-10-16T22:05:14.000Z  1317225065411346432   \n45684  2007-01-02T04:52:46.000Z               432093   \n45685  2013-08-07T09:17:18.000Z           1652517409   \n\n                                        name verified  follower_count  \\\n0                           Bitcoin Magazine     true         2521379   \n1                           Bitcoin Magazine     true         2521379   \n2                           Bitcoin Magazine     true         2521379   \n3                           Bitcoin Magazine     true         2521379   \n4                           Bitcoin Magazine     true         2521379   \n...                                      ...      ...             ...   \n45681                                 odious    false           25917   \n45682                 Artie Handz | üñºüíéüôåüèª.eth    false            8863   \n45683  Jen (Decentralized!*k) || Mint Snakes    false           14682   \n45684                                     BT     true          622334   \n45685                              jim.Bures    false              71   \n\n       following_count  tweet_count  listed_count  word_uniqueness_%  \\\n0                  765        23530         13825                100   \n1                  765        23530         13825                100   \n2                  765        23530         13825                100   \n3                  765        23530         13825                 94   \n4                  765        23530         13825                100   \n...                ...          ...           ...                ...   \n45681              971        20520           286                100   \n45682             4016         8962            94                100   \n45683             3758        17512           159                 90   \n45684             1256        17231          4425                100   \n45685               36         2271             0                100   \n\n       sentiment  \n0         0.0000  \n1         0.7184  \n2         0.4404  \n3         0.6581  \n4         0.4310  \n...          ...  \n45681     0.5782  \n45682     0.2960  \n45683     0.7003  \n45684     0.0000  \n45685     0.2732  \n\n[45686 rows x 19 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_created</th>\n      <th>conversation_id</th>\n      <th>tweet_id</th>\n      <th>author_id</th>\n      <th>text</th>\n      <th>retweet_count</th>\n      <th>reply_count</th>\n      <th>like_count</th>\n      <th>quote_count</th>\n      <th>account_created</th>\n      <th>account_id</th>\n      <th>name</th>\n      <th>verified</th>\n      <th>follower_count</th>\n      <th>following_count</th>\n      <th>tweet_count</th>\n      <th>listed_count</th>\n      <th>word_uniqueness_%</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-06-11 01:15:29+03</td>\n      <td>1535385188557103105</td>\n      <td>1535385188557103105</td>\n      <td>361289499</td>\n      <td>Texas governor candidate Don Huffines: \" Bitco...</td>\n      <td>492</td>\n      <td>267</td>\n      <td>3309</td>\n      <td>32</td>\n      <td>2011-08-24T15:14:54.000Z</td>\n      <td>361289499</td>\n      <td>Bitcoin Magazine</td>\n      <td>true</td>\n      <td>2521379</td>\n      <td>765</td>\n      <td>23530</td>\n      <td>13825</td>\n      <td>100</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-06-10 22:48:24+03</td>\n      <td>1535348174168236032</td>\n      <td>1535348174168236032</td>\n      <td>361289499</td>\n      <td>- Grayscale and Bitwise are confident a spot B...</td>\n      <td>572</td>\n      <td>258</td>\n      <td>3743</td>\n      <td>32</td>\n      <td>2011-08-24T15:14:54.000Z</td>\n      <td>361289499</td>\n      <td>Bitcoin Magazine</td>\n      <td>true</td>\n      <td>2521379</td>\n      <td>765</td>\n      <td>23530</td>\n      <td>13825</td>\n      <td>100</td>\n      <td>0.7184</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-06-10 22:08:11+03</td>\n      <td>1535338052746366977</td>\n      <td>1535338052746366977</td>\n      <td>361289499</td>\n      <td>Thanks to for publishing my article covering t...</td>\n      <td>34</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2011-08-24T15:14:54.000Z</td>\n      <td>361289499</td>\n      <td>Bitcoin Magazine</td>\n      <td>true</td>\n      <td>2521379</td>\n      <td>765</td>\n      <td>23530</td>\n      <td>13825</td>\n      <td>100</td>\n      <td>0.4404</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-06-10 22:03:21+03</td>\n      <td>1535336834070372353</td>\n      <td>1535336834070372353</td>\n      <td>361289499</td>\n      <td>Very honored that my list of Bitcoin privacy p...</td>\n      <td>68</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2011-08-24T15:14:54.000Z</td>\n      <td>361289499</td>\n      <td>Bitcoin Magazine</td>\n      <td>true</td>\n      <td>2521379</td>\n      <td>765</td>\n      <td>23530</td>\n      <td>13825</td>\n      <td>94</td>\n      <td>0.6581</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-06-10 21:40:31+03</td>\n      <td>1535331088154902529</td>\n      <td>1535331088154902529</td>\n      <td>361289499</td>\n      <td>\"And then we told them the inflation would not...</td>\n      <td>443</td>\n      <td>135</td>\n      <td>2895</td>\n      <td>28</td>\n      <td>2011-08-24T15:14:54.000Z</td>\n      <td>361289499</td>\n      <td>Bitcoin Magazine</td>\n      <td>true</td>\n      <td>2521379</td>\n      <td>765</td>\n      <td>23530</td>\n      <td>13825</td>\n      <td>100</td>\n      <td>0.4310</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>45681</th>\n      <td>2022-06-21 22:17:15+03</td>\n      <td>1539305669928669190</td>\n      <td>1539326600340193280</td>\n      <td>1287057962155094018</td>\n      <td>so cool, never stop evolving</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2020-07-25T16:11:56.000Z</td>\n      <td>1287057962155094018</td>\n      <td>odious</td>\n      <td>false</td>\n      <td>25917</td>\n      <td>971</td>\n      <td>20520</td>\n      <td>286</td>\n      <td>100</td>\n      <td>0.5782</td>\n    </tr>\n    <tr>\n      <th>45682</th>\n      <td>2022-06-21 22:09:00+03</td>\n      <td>1539305669928669190</td>\n      <td>1539324523635298306</td>\n      <td>1333917637068242944</td>\n      <td>if you want some sh*tty old trucks to paint IR...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2020-12-01T23:35:46.000Z</td>\n      <td>1333917637068242944</td>\n      <td>Artie Handz | üñºüíéüôåüèª.eth</td>\n      <td>false</td>\n      <td>8863</td>\n      <td>4016</td>\n      <td>8962</td>\n      <td>94</td>\n      <td>100</td>\n      <td>0.2960</td>\n    </tr>\n    <tr>\n      <th>45683</th>\n      <td>2022-06-21 21:03:18+03</td>\n      <td>1539305669928669190</td>\n      <td>1539307989001089026</td>\n      <td>1317225065411346432</td>\n      <td>yesssss lets go, good investment ahhhhhh this ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2020-10-16T22:05:14.000Z</td>\n      <td>1317225065411346432</td>\n      <td>Jen (Decentralized!*k) || Mint Snakes</td>\n      <td>false</td>\n      <td>14682</td>\n      <td>3758</td>\n      <td>17512</td>\n      <td>159</td>\n      <td>90</td>\n      <td>0.7003</td>\n    </tr>\n    <tr>\n      <th>45684</th>\n      <td>2022-06-21 20:57:48+03</td>\n      <td>1539305669928669190</td>\n      <td>1539306607338786818</td>\n      <td>432093</td>\n      <td>how much more epic can you get??</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2007-01-02T04:52:46.000Z</td>\n      <td>432093</td>\n      <td>BT</td>\n      <td>true</td>\n      <td>622334</td>\n      <td>1256</td>\n      <td>17231</td>\n      <td>4425</td>\n      <td>100</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>45685</th>\n      <td>2022-06-21 22:00:34+03</td>\n      <td>1539306518939676672</td>\n      <td>1539322401728647169</td>\n      <td>1652517409</td>\n      <td>Well deserved, BT. Your Metaversal release was...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2013-08-07T09:17:18.000Z</td>\n      <td>1652517409</td>\n      <td>jim.Bures</td>\n      <td>false</td>\n      <td>71</td>\n      <td>36</td>\n      <td>2271</td>\n      <td>0</td>\n      <td>100</td>\n      <td>0.2732</td>\n    </tr>\n  </tbody>\n</table>\n<p>45686 rows √ó 19 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "scope = PlotlyScope(\n",
    "    plotlyjs=\"https://cdn.plot.ly/plotly-latest.min.js\",\n",
    "    # plotlyjs=\"/path/to/local/plotly.js\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def save_graph(title, fig):\n",
    "    with open(f'./plots/{title}.png', 'wb') as f:\n",
    "        f.write(scope.transform(fig, format='png'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Daily Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df['account_created'] = pd.to_datetime(df['account_created'])\n",
    "df['tweet_created'] = pd.to_datetime(df['tweet_created'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './tml.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m./tml.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/regular/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[1;32m    310\u001B[0m     )\n\u001B[0;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/regular/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    665\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    666\u001B[0m     dialect,\n\u001B[1;32m    667\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    676\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m    677\u001B[0m )\n\u001B[1;32m    678\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/regular/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    572\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    574\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 575\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/regular/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    930\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    932\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 933\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/regular/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1213\u001B[0m     mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1214\u001B[0m \u001B[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001B[39;00m\n\u001B[1;32m   1215\u001B[0m \u001B[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[39;00m\n\u001B[1;32m   1216\u001B[0m \u001B[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[39;00m\n\u001B[0;32m-> 1217\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[call-overload]\u001B[39;49;00m\n\u001B[1;32m   1218\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1219\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1220\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1223\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1224\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1225\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1226\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1227\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1228\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/regular/lib/python3.9/site-packages/pandas/io/common.py:789\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    784\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    785\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    786\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    787\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    788\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 789\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    790\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    793\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    795\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    796\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    797\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    798\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './tml.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./tml.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "twe = df.loc[df['Date'].dt.date < datetime.date(2022, 6, 6)]\n",
    "twe_com = df.loc[df['Date'].dt.date >= datetime.date(2022, 6, 6)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "title = 'Tweet Count Daily'\n",
    "fig = px.bar(df, x='Date', y='count', title=title)\n",
    "# fig.show()\n",
    "save_graph(title, fig)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Before plotting Timeseries for BTC Close and daily sentiment for Twitter for the period from April 10 to June 19, let's take a look at tweet count per day. We can observe that we have lot more tweets in June, and that's because Twitter api allows to get comments only for past ten day, so I was able to collect comments only for starting June 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"plots/Tweet Count Daily.png\" width=700 height=400 />"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "title = 'Timeseries, Daily'\n",
    "fig = px.line(df, x='Date', y=['Close_adj', 'sentiment_adj'], title=title)\n",
    "# fig.show()\n",
    "save_graph(title, fig)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Keeping in mind that data collected starting June 5, should be much more accurate that sentiment before that. And indeed in the beginning it looks a little chaotic, but when it approaches the end of the graph it becomes much more accurate."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"plots/Timeseries, Daily.png\" width=700 height=400 />"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "title = 'Sentiment_per_Day vs BTC_close Daily'\n",
    "sns.regplot(data=df, y='Close_adj', x='sentiment_adj', x_jitter=0.01)\n",
    "plt.title(title)\n",
    "save_graph(title, fig)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### We can see that data is quite chaotic, let's take a look at its correlation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr = df[['Open', 'Close', 'High', 'Low', 'sentiment']].corr(method='pearson')\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "cmap = sns.diverging_palette(220, 255, as_cmap=True)\n",
    "sns.heatmap(data=corr, mask=mask, annot=True, cmap=cmap, fmt='.3g')\n",
    "plt.title('Correlations for Tweets&Comments Daily')\n",
    "plt.xticks(rotation=-0)\n",
    "plt.yticks(rotation=-0);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### We can see that the correlations between [Open, Close, High, Sentiment], and they are is quite low. Now let's plot everything all over again but take into account only the period of time when we have lots of tweets and comments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "title = 'Tweet & Comment Count per Daily'\n",
    "fig = px.bar(twe_com, x='Date', y='count', title=title)\n",
    "# fig.show()\n",
    "save_graph(title, fig)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"plots/Tweet & Comment Count per Daily.png\" width=700 height=400 />\n",
    "\n",
    "###### Now we will be using sentiment per day which includes on average 2500 comments per day. And I expect our results to b much more accurate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "title = 'Timeseries, Daily Tweets&Comments'\n",
    "fig = px.line(twe_com, x='Date', y=['Close_adj', 'sentiment_adj'], title=title)\n",
    "# fig.show()\n",
    "save_graph(title, fig)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"plots/Timeseries, Daily Tweets&Comments.png\" width=700 height=400 />\n",
    "\n",
    "###### And indeed, we can see that almost every time one line changes direction the other one follows. NOTE: we do not care if lines are close to each other or not, because we are no trying to predict the price, as well as BTC is measured in USD while sentiment is just an index."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.regplot(data=twe_com, y='Close_adj', x='sentiment_adj', x_jitter=0.01)\n",
    "plt.title('Average Sentiment Per Day vs BTC_close Daily, Tweets&Comments');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Here we can observe high linear relationship between two. However, unfortunately, we only have 14 point on the graph which is not statistically significant, but at the same time each point is an average of ~2500 tweets, which makes it much more meaningful."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr = twe_com[['Open', 'Close', 'High', 'Low', 'sentiment']].corr(method='pearson')\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "cmap = sns.diverging_palette(220, 255, as_cmap=True)\n",
    "sns.heatmap(data=corr, mask=mask, annot=True, cmap=cmap, fmt='.3g')\n",
    "plt.title('Correlations for Tweets&Comments Daily')\n",
    "plt.xticks(rotation=-0)\n",
    "plt.yticks(rotation=-0);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Our correlation heatmap confirms high linear relationship between BTC price and the sentiment per day."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hourly Data\n",
    "###### Now let's see how our data will react if we will be taking average per hour rather than per day. Again, this will decrease number of tweets&comments per hour."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hourly_btc = pd.read_csv('btc_hourly.csv')\n",
    "hourly_sent = pd.read_csv('hourly_sentiment.csv')\n",
    "hourly_btc['time'] = pd.to_datetime(hourly_btc['time'])\n",
    "hourly_sent.columns = ['tweet_created', 'avg_sentiment', 'tweet_count']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hourly_btc = hourly_btc.loc[(hourly_btc['time'] >= datetime.datetime(year=2022, month=6, day=6, hour=0)) & (hourly_btc['time'] <= datetime.datetime(year=2022, month=6, day=19, hour=23))]\n",
    "hourly_sent['tweet_created'] = pd.to_datetime(hourly_sent['tweet_created'], format='%y-%m-%d-%H')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hourly = pd.merge(hourly_btc, hourly_sent, left_on='time', right_on='tweet_created', how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "hourly[['open_adj', 'close_adj', 'high_adj', 'low_adj', 'sentiment_compound_adj']] = scaler.fit_transform(hourly[['open', 'close', 'high', 'low', 'avg_sentiment']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hourly.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "title = 'Tweet Count per Hour'\n",
    "fig = px.bar(hourly, x='tweet_created', y='tweet_count', title='Tweet Count per Hour')\n",
    "# fig.show()\n",
    "save_graph(title, fig)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"plots/Tweet Count per Hour.png\" width=700 height=400 />\n",
    "\n",
    "###### We can observe daily seasonality. Which is quite expected especially since the accounts that we were scraping tweets from are US located. Some hours are completely missing, the other hours have a little of comments and most of them have just over a 100, which looks quite familiar to the first graph when we were plotting tweet counts for the first month. Such seasonality is not very promising, but let's see"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "title = 'Timeseries, Hourly'\n",
    "fig = px.line(hourly, x='time', y=['close_adj', 'sentiment_compound_adj'], title=title)\n",
    "save_graph(title, fig)\n",
    "# fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"plots/Timeseries, Hourly.png\" width=700 height=400 />"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### First thing that we see is very high volatility of the sentiment and this could be explained by the low number of tweets per point. Let's plot time series where every sentiment point is at least an average of 80 tweets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hourly_sig = hourly.loc[hourly['tweet_count'] > 80]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "title = 'Timeseries, Hourly where count > 80'\n",
    "fig = px.line(hourly_sig, x='time', y=['close_adj', 'sentiment_compound_adj'], title=title)\n",
    "# fig.show()\n",
    "save_graph(title, fig)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"plots/Timeseries, Hourly where count > 80.png\" width=700 height=400 />"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Here we can see some similar behaviour of two graphs, but it is not very clear if there is an actual relationship between two. Let's take a look at the regression plots."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.regplot(data=hourly, y='close_adj', x='sentiment_compound_adj', x_jitter=0.01)\n",
    "plt.title('Average Sentiment vs BTC_close, Hourly')\n",
    "plt.show();\n",
    "sns.regplot(data=hourly_sig, y='close_adj', x='sentiment_compound_adj', x_jitter=0.01)\n",
    "plt.title('Average Sentiment vs BTC_close, Hourly where count > 80')\n",
    "plt.show();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### For the first graph it is hard to say that there is a linear relationships between two variables. However, fot the second one we can see some kind of relationship. Let's plot corr heatmaps."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr = hourly[['open', 'close', 'high', 'low', 'avg_sentiment']].corr(method='pearson')\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "cmap = sns.diverging_palette(220, 255, as_cmap=True)\n",
    "sns.heatmap(data=corr, mask=mask, annot=True, cmap=cmap, fmt='.3g')\n",
    "plt.title('Correlation for Sentiment Hourly')\n",
    "plt.xticks(rotation=-0)\n",
    "plt.yticks(rotation=-0)\n",
    "plt.show();\n",
    "corr = hourly_sig[['open', 'close', 'high', 'low', 'avg_sentiment']].corr(method='pearson')\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "cmap = sns.diverging_palette(220, 255, as_cmap=True)\n",
    "sns.heatmap(data=corr, mask=mask, annot=True, cmap=cmap, fmt='.3g')\n",
    "plt.title('Correlation for Sentiment Hourly, where count > 80')\n",
    "plt.xticks(rotation=-0)\n",
    "plt.yticks(rotation=-0)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### We can see that correlation on the first graph is quite low (~0.3), but when we use only sentiment points with at least 80 comments in it, correlation doubles from ~0.3 to 0.63. Which is quite amazing!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    "###### What we observed is that if we want to construct our timeseries hourly we need much more data per hour to be extracted. However, if we want to have our timeseries on daily basis, we have plenty of tweets, and their sentiment seems (14 days of data) to be very representative of the market behaviour."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}